{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e958559f",
   "metadata": {},
   "source": [
    "## Sequence Based Metrics\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb05664",
   "metadata": {},
   "source": [
    "### Entity Resoultion using PyPi Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417237b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install networkx==2.5\n",
    "!pip install edit-distance==1.0.4\n",
    "!pip install pandas==1.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be819a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import edit_distance  # Levenshtein distance\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2266b998",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_names = ['Los Angeles','New York City','Bangalore','Mumbai','Chennai','Kolkata','New Delhi',\\\n",
    "                'Saint Petersburg','Melbourne','Gothenburg','Vienna','Barcelona','Las Vegas']\n",
    "\n",
    "input_names = ['City of Los Angeles','New York','Bengaluru','Bombay','Madras','Calutta','Delhi',\\\n",
    "               'St. Petersburg','Melborne','Goteborg','Wien','Barca', 'Las Vegas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5df7195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_dist_metrics(actual_names, input_names, threshold):\n",
    "    '''\n",
    "    input:  list : actual_names list\n",
    "            list : input_names list\n",
    "            float : threshold value for similarity score 0 <= threshold <= 1\n",
    "            \n",
    "    The function compares every string in actual_names with every string in input_names\n",
    "    using edit_distance and provides a similarity score. If the score is more than or equal to a \n",
    "    given threshold, the two strings are matched as the same entity and compared with ground truth results.\n",
    "    The results, precision and recall is printed out.\n",
    "    '''\n",
    "    res = []\n",
    "    for i, a_name in enumerate(actual_names):\n",
    "        for j, i_name in enumerate(input_names):\n",
    "            r = edit_distance.SequenceMatcher(a_name.lower(), i_name.lower()).ratio()\n",
    "            if r >= threshold:\n",
    "                res.append([i_name, a_name, r, i==j])\n",
    "\n",
    "    df = pd.DataFrame(res, columns=['Input Name','Predicted Name','Similarity Score','Ground Truth'])\n",
    "    precision = round(sum(df['Ground Truth'])/len(df),3)\n",
    "    recall = round(sum(df['Ground Truth'])/len(actual_names),3)\n",
    "    print(df,'\\n')\n",
    "    print(\"Precision: \"+str(precision))\n",
    "    print(\"Recall: \"+str(recall))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e35a52",
   "metadata": {},
   "source": [
    "### The entity resolution is run for different threshold values\n",
    "\n",
    "### The function takes in a threshold value which is the similarity score for a pair of strings above which they are predicted as matches. The threshold value can range from 0 to 1 where 1 is a perfect match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d301ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Input Name    Predicted Name  Similarity Score  Ground Truth\n",
      "0   City of Los Angeles       Los Angeles          0.733333          True\n",
      "1             Las Vegas       Los Angeles          0.500000         False\n",
      "2              New York     New York City          0.761905          True\n",
      "3             Bengaluru         Bangalore          0.666667          True\n",
      "4                 Barca         Bangalore          0.428571         False\n",
      "5                Bombay            Mumbai          0.500000          True\n",
      "6               Calutta           Kolkata          0.428571          True\n",
      "7              New York         New Delhi          0.470588         False\n",
      "8                 Delhi         New Delhi          0.714286          True\n",
      "9        St. Petersburg  Saint Petersburg          0.800000          True\n",
      "10             Goteborg  Saint Petersburg          0.416667         False\n",
      "11             Melborne         Melbourne          0.941176          True\n",
      "12       St. Petersburg        Gothenburg          0.416667         False\n",
      "13             Goteborg        Gothenburg          0.777778          True\n",
      "14            Bengaluru            Vienna          0.400000         False\n",
      "15                 Wien            Vienna          0.600000          True\n",
      "16             Melborne         Barcelona          0.470588         False\n",
      "17                Barca         Barcelona          0.714286          True\n",
      "18               Madras         Las Vegas          0.400000         False\n",
      "19            Las Vegas         Las Vegas          1.000000          True \n",
      "\n",
      "Precision: 0.6\n",
      "Recall: 0.923\n"
     ]
    }
   ],
   "source": [
    "edit_dist_metrics(actual_names,input_names,0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "942f31ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Input Name    Predicted Name  Similarity Score  Ground Truth\n",
      "0   City of Los Angeles       Los Angeles          0.733333          True\n",
      "1             Las Vegas       Los Angeles          0.500000         False\n",
      "2              New York     New York City          0.761905          True\n",
      "3             Bengaluru         Bangalore          0.666667          True\n",
      "4                Bombay            Mumbai          0.500000          True\n",
      "5                 Delhi         New Delhi          0.714286          True\n",
      "6        St. Petersburg  Saint Petersburg          0.800000          True\n",
      "7              Melborne         Melbourne          0.941176          True\n",
      "8              Goteborg        Gothenburg          0.777778          True\n",
      "9                  Wien            Vienna          0.600000          True\n",
      "10                Barca         Barcelona          0.714286          True\n",
      "11            Las Vegas         Las Vegas          1.000000          True \n",
      "\n",
      "Precision: 0.917\n",
      "Recall: 0.846\n"
     ]
    }
   ],
   "source": [
    "edit_dist_metrics(actual_names,input_names,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "562f1d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Input Name    Predicted Name  Similarity Score  Ground Truth\n",
      "0  City of Los Angeles       Los Angeles          0.733333          True\n",
      "1             New York     New York City          0.761905          True\n",
      "2            Bengaluru         Bangalore          0.666667          True\n",
      "3                Delhi         New Delhi          0.714286          True\n",
      "4       St. Petersburg  Saint Petersburg          0.800000          True\n",
      "5             Melborne         Melbourne          0.941176          True\n",
      "6             Goteborg        Gothenburg          0.777778          True\n",
      "7                 Wien            Vienna          0.600000          True\n",
      "8                Barca         Barcelona          0.714286          True\n",
      "9            Las Vegas         Las Vegas          1.000000          True \n",
      "\n",
      "Precision: 1.0\n",
      "Recall: 0.769\n"
     ]
    }
   ],
   "source": [
    "edit_dist_metrics(actual_names,input_names,0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2221b739",
   "metadata": {},
   "source": [
    "### As the threshold increases, we can see that the precision increases but the recall decreases. A threshold value of 0.6 is ideal as it gives 100% precision with a good recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1a1ab3",
   "metadata": {},
   "source": [
    "### This threshold of 0.6 can comfortably resolve names local names against official names like 'Goteborg' v 'Gothernburg' and 'Bangalore' v 'Bengaluru' while disambiguating similar but different names like 'Los Angeles' and 'Las Vegas' . It also resolves spelling mistakes like 'Melborne' and short form of names like 'St. Petersburg'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1931c8c",
   "metadata": {},
   "source": [
    "### Q1: Try to print the pairs with edit-distance sim score higher than 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5a11198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Input Name    Predicted Name  Similarity Score  Ground Truth\n",
      "0  City of Los Angeles       Los Angeles          0.733333          True\n",
      "1             New York     New York City          0.761905          True\n",
      "2                Delhi         New Delhi          0.714286          True\n",
      "3       St. Petersburg  Saint Petersburg          0.800000          True\n",
      "4             Melborne         Melbourne          0.941176          True\n",
      "5             Goteborg        Gothenburg          0.777778          True\n",
      "6                Barca         Barcelona          0.714286          True\n",
      "7            Las Vegas         Las Vegas          1.000000          True \n",
      "\n",
      "Precision: 1.0\n",
      "Recall: 0.615\n"
     ]
    }
   ],
   "source": [
    "edit_dist_metrics(actual_names,input_names,0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a554e7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070319b8",
   "metadata": {},
   "source": [
    "## Set Based Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ef17e3",
   "metadata": {},
   "source": [
    "### 1. Jaccard Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08600733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los Angeles, City of Los Angeles\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "tokens_1 = actual_names[0]\n",
    "tokens_2 = input_names[0]\n",
    "print(f\"{tokens_1}, {tokens_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85430a99",
   "metadata": {},
   "source": [
    "### Q2: What's the Jaccard index between tokens_1 and tokens_2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12508163",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_1 = set(tokens_1.split(\" \"))\n",
    "tokens_2 = set(tokens_2.split(\" \"))\n",
    "\n",
    "jaccard_sim = len(copy.deepcopy(tokens_1).intersection(tokens_2)) / len(copy.deepcopy(tokens_1).union(tokens_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60c6c17",
   "metadata": {},
   "source": [
    "### 2. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdb44e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (3.5.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (1.0.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from spacy) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.18.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from spacy) (3.0.1)\n",
      "Requirement already satisfied: setuptools in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from spacy) (67.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from spacy) (22.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (1.6.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (3.10.0.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/keshen/opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy scikit-learn # install sklearn for a built-in TF-IDF implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bac361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_1 = \"mia's math adventure tells a captivating story with educational activities. games focus on developing math skills such as fractions geometry logic and mental computation. oh no! mia's house has just burnt down! but how could such a thing have ... \"\n",
    "desc_2 = \"in mia's math adventure: just in time children will help mia save her house by using their math skills!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30ecf71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d41cc2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTFIDFVector(doc):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(doc)\n",
    "\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    return len(feature_names), feature_names, tfidf_matrix, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1655574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 ['activities', 'adventure', 'and', 'as', 'burnt', 'but', 'by', 'captivating', 'children', 'computation', 'could', 'developing', 'down', 'educational', 'focus', 'fractions', 'games', 'geometry', 'has', 'have', 'help', 'her', 'house', 'how', 'in', 'just', 'logic', 'math', 'mental', 'mia', 'no', 'oh', 'on', 'save', 'skills', 'story', 'such', 'tells', 'their', 'thing', 'time', 'using', 'will', 'with']\n",
      "tfidf for desc_1: [[0.16423278 0.11685298 0.16423278 0.16423278 0.16423278 0.16423278\n",
      "  0.         0.16423278 0.         0.16423278 0.16423278 0.16423278\n",
      "  0.16423278 0.16423278 0.16423278 0.16423278 0.16423278 0.16423278\n",
      "  0.16423278 0.16423278 0.         0.         0.11685298 0.16423278\n",
      "  0.         0.11685298 0.16423278 0.23370595 0.16423278 0.23370595\n",
      "  0.16423278 0.16423278 0.16423278 0.         0.11685298 0.16423278\n",
      "  0.32846556 0.16423278 0.         0.16423278 0.         0.\n",
      "  0.         0.16423278]]\n",
      "tfidf for desc_2: [[0.         0.16291028 0.         0.         0.         0.\n",
      "  0.22896471 0.         0.22896471 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.22896471 0.22896471 0.16291028 0.\n",
      "  0.45792942 0.16291028 0.         0.32582055 0.         0.32582055\n",
      "  0.         0.         0.         0.22896471 0.16291028 0.\n",
      "  0.         0.         0.22896471 0.         0.22896471 0.22896471\n",
      "  0.22896471 0.        ]]\n",
      "mia's math adventure tells a captivating story with educational activities. games focus on developing math skills such as fractions geometry logic and mental computation. oh no! mia's house has just burnt down! but how could such a thing have ... \n",
      "Feature: have, TF-IDF Value: 0.16423277985774404\n",
      "Feature: thing, TF-IDF Value: 0.16423277985774404\n",
      "Feature: could, TF-IDF Value: 0.16423277985774404\n",
      "Feature: how, TF-IDF Value: 0.16423277985774404\n",
      "Feature: but, TF-IDF Value: 0.16423277985774404\n",
      "Feature: down, TF-IDF Value: 0.16423277985774404\n",
      "Feature: burnt, TF-IDF Value: 0.16423277985774404\n",
      "Feature: just, TF-IDF Value: 0.11685297550987278\n",
      "Feature: has, TF-IDF Value: 0.16423277985774404\n",
      "Feature: house, TF-IDF Value: 0.11685297550987278\n",
      "Feature: no, TF-IDF Value: 0.16423277985774404\n",
      "Feature: oh, TF-IDF Value: 0.16423277985774404\n",
      "Feature: computation, TF-IDF Value: 0.16423277985774404\n",
      "Feature: mental, TF-IDF Value: 0.16423277985774404\n",
      "Feature: and, TF-IDF Value: 0.16423277985774404\n",
      "Feature: logic, TF-IDF Value: 0.16423277985774404\n",
      "Feature: geometry, TF-IDF Value: 0.16423277985774404\n",
      "Feature: fractions, TF-IDF Value: 0.16423277985774404\n",
      "Feature: as, TF-IDF Value: 0.16423277985774404\n",
      "Feature: such, TF-IDF Value: 0.3284655597154881\n",
      "Feature: skills, TF-IDF Value: 0.11685297550987278\n",
      "Feature: developing, TF-IDF Value: 0.16423277985774404\n",
      "Feature: on, TF-IDF Value: 0.16423277985774404\n",
      "Feature: focus, TF-IDF Value: 0.16423277985774404\n",
      "Feature: games, TF-IDF Value: 0.16423277985774404\n",
      "Feature: activities, TF-IDF Value: 0.16423277985774404\n",
      "Feature: educational, TF-IDF Value: 0.16423277985774404\n",
      "Feature: with, TF-IDF Value: 0.16423277985774404\n",
      "Feature: story, TF-IDF Value: 0.16423277985774404\n",
      "Feature: captivating, TF-IDF Value: 0.16423277985774404\n",
      "Feature: tells, TF-IDF Value: 0.16423277985774404\n",
      "Feature: adventure, TF-IDF Value: 0.11685297550987278\n",
      "Feature: math, TF-IDF Value: 0.23370595101974556\n",
      "Feature: mia, TF-IDF Value: 0.23370595101974556\n",
      "in mia's math adventure: just in time children will help mia save her house by using their math skills!\n",
      "Feature: their, TF-IDF Value: 0.22896471005198588\n",
      "Feature: using, TF-IDF Value: 0.22896471005198588\n",
      "Feature: by, TF-IDF Value: 0.22896471005198588\n",
      "Feature: her, TF-IDF Value: 0.22896471005198588\n",
      "Feature: save, TF-IDF Value: 0.22896471005198588\n",
      "Feature: help, TF-IDF Value: 0.22896471005198588\n",
      "Feature: will, TF-IDF Value: 0.22896471005198588\n",
      "Feature: children, TF-IDF Value: 0.22896471005198588\n",
      "Feature: time, TF-IDF Value: 0.22896471005198588\n",
      "Feature: in, TF-IDF Value: 0.45792942010397175\n",
      "Feature: just, TF-IDF Value: 0.1629102769831016\n",
      "Feature: house, TF-IDF Value: 0.1629102769831016\n",
      "Feature: skills, TF-IDF Value: 0.1629102769831016\n",
      "Feature: adventure, TF-IDF Value: 0.1629102769831016\n",
      "Feature: math, TF-IDF Value: 0.3258205539662032\n",
      "Feature: mia, TF-IDF Value: 0.3258205539662032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keshen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "doc = [desc_1, desc_2]\n",
    "len_feature, feature_names, tfidf_matrix, vectorizer = getTFIDFVector(doc)\n",
    "print(len_feature, feature_names)\n",
    "desc_1_tfidf = tfidf_matrix[0].toarray()\n",
    "desc_2_tfidf = tfidf_matrix[1].toarray()\n",
    "print(f\"tfidf for desc_1: {desc_1_tfidf}\")\n",
    "print(f\"tfidf for desc_2: {desc_2_tfidf}\")\n",
    "\n",
    "for i in range(2):\n",
    "    print([desc_1, desc_2][i])\n",
    "    tfidf_vector = tfidf_matrix[i]\n",
    "    for feature_index, tfidf_value in zip(tfidf_vector.indices, tfidf_vector.data):\n",
    "        feature_name = feature_names[feature_index]\n",
    "        print(f\"Feature: {feature_name}, TF-IDF Value: {tfidf_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c234a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f60bbd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.22843861]]\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarity(desc_1_tfidf, desc_2_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45308063",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Remove Stop Words\"\"\"\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    processed_text = \" \".join(token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "662ee55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mia math adventure tell captivate story educational activity game focus develop math skill fraction geometry logic mental computation oh mia house burn thing\n",
      "mia math adventure time child help mia save house math skill\n"
     ]
    }
   ],
   "source": [
    "desc_1 = preprocess(desc_1)\n",
    "desc_2 = preprocess(desc_2)\n",
    "print(desc_1)\n",
    "print(desc_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9285bab4",
   "metadata": {},
   "source": [
    "### Q3: Which token(s) has the highest tf-idf value after removing the stopwords?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5146db36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.22843861]]\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarity(desc_1_tfidf, desc_2_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8f04a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_3 = \"king for a day! fritz is in charge of the castle when his parents go on vacation. it's every kid's dream until the dastardly king black challenges the young stand-in king to a duel! explore the kingdom and discover 7 arcade-style games that explai\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eba67e",
   "metadata": {},
   "source": [
    "### Q4: After we include the desc_3 into our corpus, what's the cosine similarity between desc_1 and desc_2, as well as that between desc_1 and desc_3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da1ccdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = [desc_1, desc_2, desc_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68f8b15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 ['activity', 'adventure', 'and', 'arcade', 'black', 'burn', 'captivate', 'castle', 'challenges', 'charge', 'child', 'computation', 'dastardly', 'day', 'develop', 'discover', 'dream', 'duel', 'educational', 'every', 'explai', 'explore', 'focus', 'for', 'fraction', 'fritz', 'game', 'games', 'geometry', 'go', 'help', 'his', 'house', 'in', 'is', 'it', 'kid', 'king', 'kingdom', 'logic', 'math', 'mental', 'mia', 'of', 'oh', 'on', 'parents', 'save', 'skill', 'stand', 'story', 'style', 'tell', 'that', 'the', 'thing', 'time', 'to', 'until', 'vacation', 'when', 'young']\n",
      "[[0.41795677]]\n",
      "[[0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keshen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "len_feature, feature_names, tfidf_matrix, vectorizer = getTFIDFVector(doc)\n",
    "print(len_feature, feature_names)\n",
    "desc_1_tfidf = tfidf_matrix[0].toarray()\n",
    "desc_2_tfidf = tfidf_matrix[1].toarray()\n",
    "desc_3_tfidf = tfidf_matrix[2].toarray()\n",
    "print(cosine_similarity(desc_1_tfidf, desc_2_tfidf))\n",
    "print(cosine_similarity(desc_1_tfidf, desc_3_tfidf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f295dae5",
   "metadata": {},
   "source": [
    "# Blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba24b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bda00db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'authors', 'venue', 'year'] (2616, 5)\n",
      "['id', 'title', 'authors', 'venue', 'year'] (2294, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_dblp = pd.read_csv('DBLP-ACM/DBLP2.csv', encoding='latin1')\n",
    "df_acm = pd.read_csv('DBLP-ACM/ACM.csv', encoding='latin1')\n",
    "print(df_dblp.columns.tolist(), df_dblp.shape)\n",
    "print(df_acm.columns.tolist(), df_acm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0efb1f0",
   "metadata": {},
   "source": [
    "### Blocking based on Exact Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "038789b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   id_x                                              title  \\\n",
      "0  conf/vldb/PoosalaI96  Estimation of Query-Result Distribution and it...   \n",
      "1     conf/vldb/HoelS95  Benchmarking Spatial Join Operations with Spat...   \n",
      "2   conf/vldb/KemperK94          Dual-Buffering Strategies in Object Bases   \n",
      "3  conf/vldb/ShaferAM96  SPRINT: A Scalable Parallel Classifier for Dat...   \n",
      "4      conf/vldb/CuiW01  Lineage Tracing for General Data Warehouse Tra...   \n",
      "\n",
      "                                        authors venue_x  year_x    id_y  \\\n",
      "0        Viswanath Poosala, Yannis E. Ioannidis    VLDB    1996  673321   \n",
      "1                     Erik G. Hoel, Hanan Samet    VLDB    1995  673135   \n",
      "2                Alfons Kemper, Donald Kossmann    VLDB    1994  672977   \n",
      "3  John C. Shafer, Rakesh Agrawal, Manish Mehta    VLDB    1996  673491   \n",
      "4                   Yingwei Cui, Jennifer Widom    VLDB    2001  672029   \n",
      "\n",
      "                 venue_y  year_y  \n",
      "0  Very Large Data Bases    1996  \n",
      "1  Very Large Data Bases    1995  \n",
      "2  Very Large Data Bases    1994  \n",
      "3  Very Large Data Bases    1996  \n",
      "4  Very Large Data Bases    2001   (284, 8)\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(df_dblp, df_acm, on=['title', 'authors'])\n",
    "print(merged_df.head(), merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9c524f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "journals/sigmod/Aberer03d    7\n",
      "journals/sigmod/Aberer03b    7\n",
      "journals/vldb/MaratheS02     2\n",
      "Name: id_x, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_counts = merged_df['id_x'].value_counts()\n",
    "repeated_items = value_counts[value_counts > 1]\n",
    "if len(repeated_items) > 0:\n",
    "#     print(\"Some items appeared more than once:\")\n",
    "    print(repeated_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fe18ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_ids = merged_df['id_x'].duplicated(keep=False)\n",
    "\n",
    "# Filter out the rows with duplicated 'id_x'\n",
    "merged_df = merged_df[~duplicated_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64885b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no repeated items\n"
     ]
    }
   ],
   "source": [
    "value_counts = merged_df['id_y'].value_counts()\n",
    "repeated_items = value_counts[value_counts > 1]\n",
    "if len(repeated_items) > 0:\n",
    "#     print(\"Some items appeared more than once:\")\n",
    "    print(repeated_items)\n",
    "else:\n",
    "    print(\"no repeated items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed96d59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268, 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96402058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_x</th>\n",
       "      <th>id_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conf/vldb/PoosalaI96</td>\n",
       "      <td>673321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conf/vldb/HoelS95</td>\n",
       "      <td>673135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conf/vldb/KemperK94</td>\n",
       "      <td>672977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>conf/vldb/ShaferAM96</td>\n",
       "      <td>673491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>conf/vldb/CuiW01</td>\n",
       "      <td>672029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>journals/vldb/Atkinson00</td>\n",
       "      <td>765234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>conf/vldb/HanF95</td>\n",
       "      <td>673134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>conf/vldb/Suciu96a</td>\n",
       "      <td>673488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>conf/vldb/GinisHKMT97</td>\n",
       "      <td>670997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>conf/vldb/Gentili01</td>\n",
       "      <td>672184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id_x    id_y\n",
       "0        conf/vldb/PoosalaI96  673321\n",
       "1           conf/vldb/HoelS95  673135\n",
       "2         conf/vldb/KemperK94  672977\n",
       "3        conf/vldb/ShaferAM96  673491\n",
       "4            conf/vldb/CuiW01  672029\n",
       "..                        ...     ...\n",
       "279  journals/vldb/Atkinson00  765234\n",
       "280          conf/vldb/HanF95  673134\n",
       "281        conf/vldb/Suciu96a  673488\n",
       "282     conf/vldb/GinisHKMT97  670997\n",
       "283       conf/vldb/Gentili01  672184\n",
       "\n",
       "[268 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[['id_x', 'id_y']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a301f6c",
   "metadata": {},
   "source": [
    "# Q1: If we only use the title to do the exact match, how many pairs we can find between the two datasets?After we remove the repeated id, how many exact pairs we can directly get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e98eb5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     id_x                                              title  \\\n",
      "0    conf/vldb/PoosalaI96  Estimation of Query-Result Distribution and it...   \n",
      "1  conf/vldb/GardarinGT96  Cost-based Selection of Path Expression Proces...   \n",
      "2       conf/vldb/HoelS95  Benchmarking Spatial Join Operations with Spat...   \n",
      "3     conf/vldb/KemperK94          Dual-Buffering Strategies in Object Bases   \n",
      "4  journals/vldb/ChangG01  Approximate query mapping: Accounting for tran...   \n",
      "\n",
      "                                           authors_x  venue_x  year_x    id_y  \\\n",
      "0             Viswanath Poosala, Yannis E. Ioannidis     VLDB    1996  673321   \n",
      "1  Zhao-Hui Tang, Georges Gardarin, Jean-Robert G...     VLDB    1996  673484   \n",
      "2                          Erik G. Hoel, Hanan Samet     VLDB    1995  673135   \n",
      "3                     Alfons Kemper, Donald Kossmann     VLDB    1994  672977   \n",
      "4       Hector Garcia-Molina, Kevin Chen-Chuan Chang  VLDB J.    2001  767145   \n",
      "\n",
      "                                           authors_y  \\\n",
      "0             Viswanath Poosala, Yannis E. Ioannidis   \n",
      "1  Georges Gardarin, Jean-Robert Gruser, Zhao-Hui...   \n",
      "2                          Erik G. Hoel, Hanan Samet   \n",
      "3                     Alfons Kemper, Donald Kossmann   \n",
      "4  Kevin Chen-Chuan Chang, H&#233;ctor Garc&#237;...   \n",
      "\n",
      "                                             venue_y  year_y  \n",
      "0                              Very Large Data Bases    1996  \n",
      "1                              Very Large Data Bases    1996  \n",
      "2                              Very Large Data Bases    1995  \n",
      "3                              Very Large Data Bases    1994  \n",
      "4  The VLDB Journal &mdash; The International Jou...    2001   (988, 9)\n"
     ]
    }
   ],
   "source": [
    "merged_df_ = pd.merge(df_dblp, df_acm, on='title')\n",
    "print(merged_df_.head(), merged_df_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66586963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_x</th>\n",
       "      <th>id_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conf/vldb/PoosalaI96</td>\n",
       "      <td>673321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conf/vldb/GardarinGT96</td>\n",
       "      <td>673484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conf/vldb/HoelS95</td>\n",
       "      <td>673135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>conf/vldb/KemperK94</td>\n",
       "      <td>672977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>journals/vldb/ChangG01</td>\n",
       "      <td>767145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>conf/vldb/AndreiV01</td>\n",
       "      <td>672357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>journals/tods/KarpSP03</td>\n",
       "      <td>762473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>journals/tods/ChakrabartiKMP02</td>\n",
       "      <td>375680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>journals/tods/ChakrabartiKMP02</td>\n",
       "      <td>568520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>conf/vldb/LiM01</td>\n",
       "      <td>672035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>988 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id_x    id_y\n",
       "0              conf/vldb/PoosalaI96  673321\n",
       "1            conf/vldb/GardarinGT96  673484\n",
       "2                 conf/vldb/HoelS95  673135\n",
       "3               conf/vldb/KemperK94  672977\n",
       "4            journals/vldb/ChangG01  767145\n",
       "..                              ...     ...\n",
       "983             conf/vldb/AndreiV01  672357\n",
       "984          journals/tods/KarpSP03  762473\n",
       "985  journals/tods/ChakrabartiKMP02  375680\n",
       "986  journals/tods/ChakrabartiKMP02  568520\n",
       "987                 conf/vldb/LiM01  672035\n",
       "\n",
       "[988 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_[['id_x', 'id_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d40e9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "journals/sigmod/Aberer03d                7\n",
      "journals/sigmod/Aberer03b                7\n",
      "journals/vldb/AbbadiSW01                 6\n",
      "journals/vldb/Atkinson00                 6\n",
      "journals/vldb/BernsteinIR03              6\n",
      "journals/vldb/AtluriJY03                 6\n",
      "journals/tods/Snodgrass01a               3\n",
      "journals/tods/Snodgrass01                3\n",
      "journals/vldb/ApersCS02                  3\n",
      "journals/sigmod/RossHLW01                2\n",
      "journals/sigmod/RossFLOSSVW00            2\n",
      "journals/sigmod/RossCGLLM01              2\n",
      "journals/sigmod/CherniakV03              2\n",
      "journals/sigmod/RossAKSSY00              2\n",
      "journals/sigmod/RossIJP00                2\n",
      "journals/sigmod/RossGR03                 2\n",
      "journals/sigmod/Snodgrass99b             2\n",
      "journals/vldb/MaratheS02                 2\n",
      "journals/sigmod/RossHKRRSS01             2\n",
      "journals/sigmod/RossKMV02                2\n",
      "journals/tods/ChakrabartiKMP02           2\n",
      "journals/sigmod/SnodgrassGIMSU98         2\n",
      "journals/sigmod/RossFS02                 2\n",
      "journals/sigmod/RossAA02                 2\n",
      "journals/sigmod/Snodgrass98a             2\n",
      "journals/sigmod/SnodgrassHMOPRRWY98      2\n",
      "journals/sigmod/GottlobKP03a             2\n",
      "journals/sigmod/SnodgrassACFLLORRSV99    2\n",
      "journals/sigmod/RossNO03                 2\n",
      "journals/vldb/Halevy02                   2\n",
      "journals/sigmod/RossCGJBV99              2\n",
      "journals/sigmod/RossAJS02                2\n",
      "Name: id_x, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_counts = merged_df_['id_x'].value_counts()\n",
    "repeated_items = value_counts[value_counts > 1]\n",
    "if len(repeated_items) > 0:\n",
    "#     print(\"Some items appeared more than once:\")\n",
    "    print(repeated_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d652216",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_ids = merged_df_['id_x'].duplicated(keep=False)\n",
    "\n",
    "# Filter out the rows with duplicated 'id_x'\n",
    "merged_df_ = merged_df_[~duplicated_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e96c8c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277955    2\n",
      "671202    2\n",
      "673643    2\n",
      "672990    2\n",
      "Name: id_y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_counts = merged_df_['id_y'].value_counts()\n",
    "repeated_items = value_counts[value_counts > 1]\n",
    "if len(repeated_items) > 0:\n",
    "#     print(\"Some items appeared more than once:\")\n",
    "    print(repeated_items)\n",
    "else:\n",
    "    print(\"no repeated items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8abc86d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_ids = merged_df_['id_y'].duplicated(keep=False)\n",
    "\n",
    "# Filter out the rows with duplicated 'id_x'\n",
    "merged_df_ = merged_df_[~duplicated_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22e444f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_x</th>\n",
       "      <th>id_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>conf/vldb/PoosalaI96</td>\n",
       "      <td>673321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>conf/vldb/GardarinGT96</td>\n",
       "      <td>673484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conf/vldb/HoelS95</td>\n",
       "      <td>673135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>conf/vldb/KemperK94</td>\n",
       "      <td>672977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>journals/vldb/ChangG01</td>\n",
       "      <td>767145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>conf/vldb/ChungCLL01</td>\n",
       "      <td>672347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>conf/vldb/WienerN94</td>\n",
       "      <td>672979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>conf/vldb/AndreiV01</td>\n",
       "      <td>672357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>journals/tods/KarpSP03</td>\n",
       "      <td>762473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>conf/vldb/LiM01</td>\n",
       "      <td>672035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id_x    id_y\n",
       "0      conf/vldb/PoosalaI96  673321\n",
       "1    conf/vldb/GardarinGT96  673484\n",
       "2         conf/vldb/HoelS95  673135\n",
       "3       conf/vldb/KemperK94  672977\n",
       "4    journals/vldb/ChangG01  767145\n",
       "..                      ...     ...\n",
       "981    conf/vldb/ChungCLL01  672347\n",
       "982     conf/vldb/WienerN94  672979\n",
       "983     conf/vldb/AndreiV01  672357\n",
       "984  journals/tods/KarpSP03  762473\n",
       "987         conf/vldb/LiM01  672035\n",
       "\n",
       "[887 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_[['id_x', 'id_y']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9ccfdb",
   "metadata": {},
   "source": [
    "### Token-based Blocking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f495e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter df_acm and df_dblp to keep rows not present in merged_df\n",
    "merged_titles = merged_df['title'].values\n",
    "df_dblp = df_dblp[~df_dblp['title'].isin(merged_titles)]\n",
    "df_acm = df_acm[~df_acm['title'].isin(merged_titles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "656fe6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SIGMOD Record' 'VLDB' 'SIGMOD Conference' 'VLDB J.'\n",
      " 'ACM Trans. Database Syst.']\n",
      "['International Conference on Management of Data' 'ACM SIGMOD Record '\n",
      " 'ACM Transactions on Database Systems (TODS) '\n",
      " 'The VLDB Journal &mdash; The International Journal on Very Large Data Bases '\n",
      " 'Very Large Data Bases']\n"
     ]
    }
   ],
   "source": [
    "dblp_venue_unique_items = df_dblp['venue'].unique()\n",
    "print(dblp_venue_unique_items)\n",
    "\n",
    "acm_venue_unique_items = df_acm['venue'].unique()\n",
    "print(acm_venue_unique_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "798f37f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['International Conference on Management of Data' 'SIGMOD Record'\n",
      " 'ACM Trans. Database Syst.' 'VLDB J.' 'VLDB']\n"
     ]
    }
   ],
   "source": [
    "replacements = {\n",
    "    'ACM SIGMOD Record ': 'SIGMOD Record',\n",
    "    'Very Large Data Bases': 'VLDB',\n",
    "    'The VLDB Journal &mdash; The International Journal on Very Large Data Bases ': 'VLDB J.',\n",
    "    'ACM Transactions on Database Systems (TODS) ': 'ACM Trans. Database Syst.',\n",
    "    \n",
    "}\n",
    "\n",
    "df_acm['venue'] = df_acm['venue'].replace(replacements)\n",
    "print(df_acm['venue'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5d3a9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(494, 5) (565, 5)\n",
      "(443, 5) (681, 5)\n",
      "(186, 5) (192, 5)\n",
      "(123, 5) (123, 5)\n"
     ]
    }
   ],
   "source": [
    "for venue in ['SIGMOD Record', 'VLDB', 'VLDB J.', 'ACM Trans. Database Syst.']:\n",
    "    filtered_dblp = df_dblp[df_dblp['venue'] == venue]\n",
    "    filtered_acm = df_acm[df_acm['venue'] == venue]\n",
    "    print(filtered_acm.shape, filtered_dblp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77e73907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_dist_metrics(df1, df2, threshold):\n",
    "    '''\n",
    "    input:  DataFrame : df1\n",
    "            DataFrame : df2\n",
    "            float : threshold value for similarity score 0 <= threshold <= 1\n",
    "    '''\n",
    "    res = []\n",
    "    for i, row1 in df1.iterrows():\n",
    "        for j, row2 in df2.iterrows():\n",
    "            title1 = row1['title']\n",
    "            title2 = row2['title']\n",
    "            similarity_score1 = edit_distance.SequenceMatcher(title1.lower(), title2.lower()).ratio()\n",
    "            \n",
    "            authors1 = row1['authors']\n",
    "            authors2 = row2['authors']\n",
    "            similarity_score2 = edit_distance.SequenceMatcher(authors1.lower(), authors2.lower()).ratio()\n",
    "            \n",
    "            acmid = row1['id']\n",
    "            dblpid = row2['id']\n",
    "            if (similarity_score1+similarity_score2)/2 >= threshold:\n",
    "                res.append([acmid, dblpid, (similarity_score1+similarity_score2)/2])\n",
    "\n",
    "    df = pd.DataFrame(res, columns=['ACM id', 'DBLP id', 'Similarity Score'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "713c25e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_acm_ACMTrans = filtered_acm[filtered_acm['venue'] == 'ACM Trans. Database Syst.']\n",
    "filtered_dblp_ACMTrans = filtered_dblp[filtered_dblp['venue'] == 'ACM Trans. Database Syst.']\n",
    "\n",
    "edit_dis = edit_dist_metrics(filtered_acm_ACMTrans, filtered_dblp_ACMTrans, 0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c02925b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ACM id                           DBLP id  Similarity Score  ACM id Count  \\\n",
      "0    331986       journals/tods/MuralidharS99          1.000000             1   \n",
      "1    331984             journals/tods/DeySB99          0.843750             1   \n",
      "6    331989            journals/tods/WandSW99          0.694444             1   \n",
      "7    310710          journals/tods/DattaVCK99          0.822581             1   \n",
      "8    320252         journals/tods/GravanoGT99          0.723214             1   \n",
      "..      ...                               ...               ...           ...   \n",
      "119  958948        journals/tods/HjaltasonS03          0.983871             1   \n",
      "120  958943             journals/tods/TaoSP03          0.750000             1   \n",
      "121  937600            journals/tods/JacoxS03          0.648148             1   \n",
      "122  937601  journals/tods/Jimenez-PerisPAK03          0.827160             1   \n",
      "123  937599     journals/tods/WijesekeraJPH03          0.750000             1   \n",
      "\n",
      "     DBLP id Count  \n",
      "0                1  \n",
      "1                1  \n",
      "6                1  \n",
      "7                1  \n",
      "8                1  \n",
      "..             ...  \n",
      "119              1  \n",
      "120              1  \n",
      "121              1  \n",
      "122              1  \n",
      "123              1  \n",
      "\n",
      "[108 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "acm_counts = edit_dis['ACM id'].value_counts().reset_index()\n",
    "dblp_counts = edit_dis['DBLP id'].value_counts().reset_index()\n",
    "\n",
    "# Rename the columns to avoid conflicts during merging\n",
    "acm_counts = acm_counts.rename(columns={'index': 'ACM id', 'ACM id': 'ACM id Count'})\n",
    "dblp_counts = dblp_counts.rename(columns={'index': 'DBLP id', 'DBLP id': 'DBLP id Count'})\n",
    "\n",
    "# Merge the count DataFrames with 'edit_dis' DataFrame\n",
    "merged_edit_dis = pd.merge(edit_dis, acm_counts, on='ACM id')\n",
    "merged_edit_dis = pd.merge(merged_edit_dis, dblp_counts, on='DBLP id')\n",
    "\n",
    "# Filter the DataFrame based on IDs that appear only once in both columns\n",
    "AMCTrans_Match = merged_edit_dis[(merged_edit_dis['ACM id Count'] == 1) & (merged_edit_dis['DBLP id Count'] == 1)]\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "print(AMCTrans_Match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "173ce7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACM id</th>\n",
       "      <th>DBLP id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>331986</td>\n",
       "      <td>journals/tods/MuralidharS99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>331984</td>\n",
       "      <td>journals/tods/DeySB99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>331989</td>\n",
       "      <td>journals/tods/WandSW99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>310710</td>\n",
       "      <td>journals/tods/DattaVCK99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>320252</td>\n",
       "      <td>journals/tods/GravanoGT99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>958948</td>\n",
       "      <td>journals/tods/HjaltasonS03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>958943</td>\n",
       "      <td>journals/tods/TaoSP03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>937600</td>\n",
       "      <td>journals/tods/JacoxS03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>937601</td>\n",
       "      <td>journals/tods/Jimenez-PerisPAK03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>937599</td>\n",
       "      <td>journals/tods/WijesekeraJPH03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ACM id                           DBLP id\n",
       "0    331986       journals/tods/MuralidharS99\n",
       "1    331984             journals/tods/DeySB99\n",
       "6    331989            journals/tods/WandSW99\n",
       "7    310710          journals/tods/DattaVCK99\n",
       "8    320252         journals/tods/GravanoGT99\n",
       "..      ...                               ...\n",
       "119  958948        journals/tods/HjaltasonS03\n",
       "120  958943             journals/tods/TaoSP03\n",
       "121  937600            journals/tods/JacoxS03\n",
       "122  937601  journals/tods/Jimenez-PerisPAK03\n",
       "123  937599     journals/tods/WijesekeraJPH03\n",
       "\n",
       "[108 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMCTrans_Match[['ACM id', 'DBLP id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e844f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 5) (15, 5)\n"
     ]
    }
   ],
   "source": [
    "acm_ACMTrans_id = filtered_acm_ACMTrans[['id']]\n",
    "dblp_ACMTrans_id = filtered_dblp_ACMTrans[['id']]\n",
    "\n",
    "filtered_acm_edit_dis = filtered_acm_ACMTrans[~filtered_acm_ACMTrans['id'].isin(AMCTrans_Match[['ACM id', 'DBLP id']]['ACM id'])]\n",
    "filtered_dblp_edit_dis = filtered_dblp_ACMTrans[~filtered_dblp_ACMTrans['id'].isin(AMCTrans_Match[['ACM id', 'DBLP id']]['DBLP id'])]\n",
    "\n",
    "print(filtered_acm_edit_dis.shape, filtered_dblp_edit_dis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "49ec83cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ACM id                     DBLP id  Similarity Score  ACM id Count  \\\n",
      "2   331992        journals/tods/YanG99          1.000000             2   \n",
      "3   176573        journals/tods/YanG99          0.623147             2   \n",
      "4   331992        journals/tods/YanG94          0.717742             2   \n",
      "5   176573        journals/tods/YanG94          0.905405             2   \n",
      "41  505049  journals/tods/Snodgrass01a          0.959459             2   \n",
      "42  505055  journals/tods/Snodgrass01a          0.959459             2   \n",
      "43  505049   journals/tods/Snodgrass01          0.959459             2   \n",
      "44  505055   journals/tods/Snodgrass01          0.959459             2   \n",
      "55  569785         journals/tods/Kim94          0.666667             1   \n",
      "56  569784         journals/tods/Kim94          0.877778             1   \n",
      "75  211416        journals/tods/Chen95          0.686441             2   \n",
      "76  202110        journals/tods/Chen95          1.000000             2   \n",
      "77  211416       journals/tods/Chen95a          1.000000             2   \n",
      "78  202110       journals/tods/Chen95a          0.686441             2   \n",
      "91  185828     journals/tods/CeriFPT94          0.884615             2   \n",
      "92  185828     journals/tods/CeriFPT95          0.773718             2   \n",
      "\n",
      "    DBLP id Count  \n",
      "2               2  \n",
      "3               2  \n",
      "4               2  \n",
      "5               2  \n",
      "41              2  \n",
      "42              2  \n",
      "43              2  \n",
      "44              2  \n",
      "55              2  \n",
      "56              2  \n",
      "75              2  \n",
      "76              2  \n",
      "77              2  \n",
      "78              2  \n",
      "91              1  \n",
      "92              1  \n"
     ]
    }
   ],
   "source": [
    "filtered_edit_dis = merged_edit_dis[(merged_edit_dis['ACM id Count'] != 1) | (merged_edit_dis['DBLP id Count'] != 1)]\n",
    "print(filtered_edit_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c69e1048",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus1 = df_acm['title'].tolist()\n",
    "\n",
    "corpus2 = df_dblp['title'].tolist()\n",
    "\n",
    "corpus1.extend(corpus2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5f09c983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3261\n",
      "331992 journals/tods/YanG99\n",
      "The SIFT information dissemination system\n",
      "The SIFT Information Dissemination System\n",
      "1.0\n",
      "--------\n",
      "176573 journals/tods/YanG99\n",
      "Index structures for selective dissemination of information under the Boolean model\n",
      "The SIFT Information Dissemination System\n",
      "0.31177412953716754\n",
      "--------\n",
      "331992 journals/tods/YanG94\n",
      "The SIFT information dissemination system\n",
      "Index Structures for Selective Dissemination of Information Under the Boolean Model\n",
      "0.31177412953716754\n",
      "--------\n",
      "176573 journals/tods/YanG94\n",
      "Index structures for selective dissemination of information under the Boolean model\n",
      "Index Structures for Selective Dissemination of Information Under the Boolean Model\n",
      "1.0\n",
      "--------\n",
      "505049 journals/tods/Snodgrass01a\n",
      "Editorial\n",
      "Editorial\n",
      "1.0\n",
      "--------\n",
      "505055 journals/tods/Snodgrass01a\n",
      "Editorial\n",
      "Editorial\n",
      "1.0\n",
      "--------\n",
      "505049 journals/tods/Snodgrass01\n",
      "Editorial\n",
      "Editorial\n",
      "1.0\n",
      "--------\n",
      "505055 journals/tods/Snodgrass01\n",
      "Editorial\n",
      "Editorial\n",
      "1.0\n",
      "--------\n",
      "569785 journals/tods/Kim94\n",
      "Editorial directons\n",
      "Charter and Scope\n",
      "0.0\n",
      "--------\n",
      "569784 journals/tods/Kim94\n",
      "Editorial: Charter and scope\n",
      "Charter and Scope\n",
      "0.8668471738818802\n",
      "--------\n",
      "211416 journals/tods/Chen95\n",
      "Query evaluation in deductive databases with alternating fixpoint semantics\n",
      "Declarative Updates of Relational Databases\n",
      "0.058719279106965214\n",
      "--------\n",
      "202110 journals/tods/Chen95\n",
      "Declarative updates of relational databases\n",
      "Declarative Updates of Relational Databases\n",
      "1.0\n",
      "--------\n",
      "211416 journals/tods/Chen95a\n",
      "Query evaluation in deductive databases with alternating fixpoint semantics\n",
      "Query Evaluation in Deductive Databases with Alternating Fixpoint Semantics\n",
      "1.0\n",
      "--------\n",
      "202110 journals/tods/Chen95a\n",
      "Declarative updates of relational databases\n",
      "Query Evaluation in Deductive Databases with Alternating Fixpoint Semantics\n",
      "0.058719279106965214\n",
      "--------\n",
      "185828 journals/tods/CeriFPT94\n",
      "Automatic generation of production rules for integrity maintenance\n",
      "Automatic Generation of Production Rules for Integrity Maintenance\n",
      "1.0\n",
      "--------\n",
      "185828 journals/tods/CeriFPT95\n",
      "Automatic generation of production rules for integrity maintenance\n",
      "Addendum to Automatic Generation of Production Rules for Integrity Maintenance\n",
      "0.8497098579799682\n",
      "--------\n",
      "{331992: {'journals/tods/YanG99': 1.0, 'journals/tods/YanG94': 0.31177412953716754}, 176573: {'journals/tods/YanG99': 0.31177412953716754, 'journals/tods/YanG94': 1.0}, 505049: {'journals/tods/Snodgrass01a': 1.0, 'journals/tods/Snodgrass01': 1.0}, 505055: {'journals/tods/Snodgrass01a': 1.0, 'journals/tods/Snodgrass01': 1.0}, 569785: {'journals/tods/Kim94': 0.0}, 569784: {'journals/tods/Kim94': 0.8668471738818802}, 211416: {'journals/tods/Chen95': 0.058719279106965214, 'journals/tods/Chen95a': 1.0}, 202110: {'journals/tods/Chen95': 1.0, 'journals/tods/Chen95a': 0.058719279106965214}, 185828: {'journals/tods/CeriFPT94': 1.0, 'journals/tods/CeriFPT95': 0.8497098579799682}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keshen/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "len_feature, feature_names, tfidf_matrix, vectorizer = getTFIDFVector(corpus1)\n",
    "print(len_feature)\n",
    "# filtered_acm_ACMTrans, filtered_dblp_ACMTrans\n",
    "tfidf_dict = {}\n",
    "for i, row in filtered_edit_dis.iterrows():\n",
    "    print(row['ACM id'], row['DBLP id'])\n",
    "    title1 = filtered_acm_ACMTrans[filtered_acm_ACMTrans['id'] == row['ACM id']]['title'].tolist()[0]\n",
    "    title2 = filtered_dblp_ACMTrans[filtered_dblp_ACMTrans['id'] == row['DBLP id']]['title'].tolist()[0]\n",
    "    print(title1)\n",
    "    print(title2)\n",
    "    tfidf1 = vectorizer.transform([title1]).toarray()\n",
    "    tfidf2 = vectorizer.transform([title2]).toarray()\n",
    "    print(cosine_similarity(tfidf1, tfidf2)[0][0])\n",
    "    if row['ACM id'] not in tfidf_dict:\n",
    "        tfidf_dict[row['ACM id']] = {row['DBLP id']: cosine_similarity(tfidf1, tfidf2)[0][0]}\n",
    "    else:\n",
    "        tfidf_dict[row['ACM id']][row['DBLP id']] = cosine_similarity(tfidf1, tfidf2)[0][0]\n",
    "    print('--------')\n",
    "print(tfidf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d5539675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 [(331992, 'journals/tods/YanG99'), (176573, 'journals/tods/YanG94'), (505049, 'journals/tods/Snodgrass01a'), (505055, 'journals/tods/Snodgrass01a'), (569785, 'journals/tods/Kim94'), (569784, 'journals/tods/Kim94'), (211416, 'journals/tods/Chen95a'), (202110, 'journals/tods/Chen95'), (185828, 'journals/tods/CeriFPT94')]\n"
     ]
    }
   ],
   "source": [
    "pairs = [(key, max(value, key=value.get)) for key, value in tfidf_dict.items()]\n",
    "print(len(pairs), pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "43721af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.8668471738818802\n",
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_dict[569785]['journals/tods/Kim94'], tfidf_dict[569784]['journals/tods/Kim94'], )\n",
    "print(tfidf_dict[505049]['journals/tods/Snodgrass01a'], tfidf_dict[505055]['journals/tods/Snodgrass01a'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b387cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "pairs.remove((569785, 'journals/tods/Kim94'))\n",
    "print(len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a628ce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 5) (8, 5)\n"
     ]
    }
   ],
   "source": [
    "acm_ACMTrans_id = filtered_acm_edit_dis[['id']]\n",
    "dblp_ACMTrans_id = filtered_dblp_edit_dis[['id']]\n",
    "\n",
    "filtered_acm_edit_dis = filtered_acm_edit_dis[~filtered_acm_edit_dis['id'].isin([p[0]for p in pairs])]\n",
    "filtered_dblp_edit_dis = filtered_dblp_edit_dis[~filtered_dblp_edit_dis['id'].isin([p[1]for p in pairs])]\n",
    "\n",
    "print(filtered_acm_edit_dis.shape, filtered_dblp_edit_dis.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68133824",
   "metadata": {},
   "source": [
    "# Q2: Recall that we have title, year, authors, and venue as data attributes provided in the dataset, is there any other among these will be a good choice to set up blocking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4928e503",
   "metadata": {},
   "outputs": [],
   "source": [
    "dblp_year_unique_items = df_dblp['year'].unique()\n",
    "print(sorted(dblp_year_unique_items))\n",
    "\n",
    "acm_year_unique_items = df_acm['year'].unique()\n",
    "print(sorted(acm_year_unique_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382cb7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
